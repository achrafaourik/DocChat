Prompt Engineering and LLMs with Langchain | Pinecone 
Log In 
Sign Up Free 
Sign In 
Create Account 
 
 
Toggle menu 
Prompt Engineering and LLMs with Langchain 
We have always relied on different models for different tasks in machine learning. With the introduction of 
multi-modality 
 and Large Language Models (LLMs), this has changed.
Gone are the days when we needed separate models for classification, named entity recognition (NER), question-answering (QA), and many other tasks.
 
 
Before transfer learning, different tasks and use cases required training different models.
With the introduction of transformers and 
transfer learning 
, all that was needed to adapt a language model for different tasks was a few small layers at the end of the network (the 
head 
) and a little fine-tuning.
 
 
Transformers and the idea of 
transfer learning 
 allowed us to reuse the same core components of pretrained transformer models for different tasks by switching model “heads” and performing fine-tuning.
Today, even that approach is outdated. Why change these last few model layers and go through an entire fine-tuning process when you can prompt the model to do classification or QA.
 
 
Many tasks can be performed using the same 
L 
arge 
L 
anguage 
M 
odels (LLMs) by simply changing the instructions in the prompts.
L 
arge 
L 
anguage 
M 
odels (LLMs) can perform all these tasks and more. These models have been trained with a simple concept, you input a sequence of text, and the model outputs a sequence of text. The one variable here is the input text — the prompt.
In this new age of LLMs, prompts are king. Bad prompts produce bad outputs, and good prompts are unreasonably powerful. Constructing good prompts is a crucial skill for those building with LLMs.
The 
LangChain 
library recognizes the power of prompts and has built an entire set of objects for them. In this article, we will learn all there is to know about 
 and implementing them effectively.
Prompt Engineering 
Before diving into Langchain’s 
, we need to better understand prompts and the discipline of prompt engineering.
A prompt is typically composed of multiple parts: 
 
 
A typical prompt structure.
Not all prompts use these components, but a good prompt often uses two or more. Let’s define them more precisely.
Instructions 
 tell the model what to do, how to use external information if provided, what to do with the query, and how to construct the output.
External information 
or 
context(s) 
 act as an additional source of knowledge for the model. These can be manually inserted into the prompt, retrieved via a vector database (retrieval augmentation), or pulled in via other means (APIs, calculations, etc.).
User input 
or 
query 
is typically (but not always) a query input into the system by a human user (the 
prompter 
). 
Output indicator 
marks the 
beginning 
of the to-be-generated text. If generating Python code, we may use 
to indicate to the model that it must begin writing Python code (as most Python scripts begin with 
). 
Each component is usually placed in the prompt in this order. Starting with instructions, external information (where applicable), prompter input, and finally, the output indicator.
Let’s see how we’d feed this into an OpenAI model using Langchain: 
In[5]: 
In[6]: 
In[7]: 
Out[7]: 
In reality, we’re unlikely to hardcode the context and user question. We’d feed them in via a 
template 
— which is where Langchain’s 
 comes in.
Prompt Templates 
The prompt template classes in Langchain are built to make constructing prompts with dynamic inputs easier. Of these classes, the simplest is the 
. We’ll test this by adding a single dynamic input to our previous prompt, the user 
. 
With this, we can use the 
method on our 
to see the effect of passing a 
 to the template.
In[9]: 
Out[9]: 
Naturally, we can pass the output of this directly into an LLM object like so: 
In[10]: 
Out[10]: 
This is just a simple implementation that can easily be replaced with f-strings (like 
). However, using Langchain’s 
 object, we can formalize the process, add multiple parameters, and build prompts with an object-oriented approach.
These are significant advantages, but only some of what Langchain offers to help us with prompts.
Few Shot Prompt Templates 
The success of LLMs comes from their large size and ability to store “knowledge” within the model parameter, which is 
learned 
during model training. However, there are more ways to pass knowledge to an LLM. The two primary methods are: 
Parametric knowledge 
— the knowledge mentioned above is anything that has been learned by the model during training time and is stored within the model weights (or 
parameters 
). 
Source knowledge 
 — any knowledge provided to the model at inference time via the input prompt.
Langchain’s 
caters to 
source knowledge 
input. The idea is to “train” the model on a few examples — we call this 
few-shot learning 
 — and these examples are given to the model within the prompt.
Few-shot learning is perfect when our model needs help understanding what we’re asking it to do. We can see this in the following example: 
In[12]: 
Out[12]: 
In this case, we’re asking for something amusing, a joke, in return to our serious question. However, we get a serious response even with the 
— which increases randomness/creativity — set to 
. 
To help the model, we can give it a few examples of the type of answers we’d like: 
In[13]: 
Out[13]: 
With our examples reinforcing the instructions we passed in the prompt, we’re much more likely to get a more amusing response. We can then formalize this process with Langchain’s 
: 
If we then pass in the 
and user 
, we will get this: 
In[15]: 
Out[15]: 
This process can seem somewhat convoluted. Why do all of this with a 
object, the 
 dictionary, etc. — when we can do the same with a few lines of code and an f-string?
Again, this approach is more formalized, integrates well with other features in Langchain (such as chains — more on this soon), and comes with several features. One of those is the ability to vary the number of examples to be included based on query length.
A dynamic number of examples is important because the maximum length of our prompt and completion output is limited. This limitation is measured by the 
maximum context window 
. 
$$ 
context \space window = input \space tokens + output \space tokens 
$$ 
At the same time, we can 
maximize 
 the number of examples given to the model for few-shot learning.
Considering this, we need to balance the number of examples included and our prompt size. Our 
hard limit 
is the maximum context size, but we must also consider the 
cost 
of processing more tokens through the LLM. Fewer tokens mean a cheaper service 
and 
 faster completions from the LLM.
The 
allows us to vary the number of examples included based on these variables. First, we create a more extensive list of 
: 
After this, rather than passing the 
directly, we actually use a 
like so: 
It’s important to note that we’re measuring the 
as the number of words determined by splitting the string by spaces and newlines. The exact logic looks like this: 
In[30]: 
Out[30]: 
We then pass our 
to the 
to create a new — and dynamic — prompt template: 
Now if we pass a shorter or longer query, we should see that the number of included examples will vary.
In[32]: 
Out[32]: 
Passing a longer question will result in fewer examples being included: 
In[34]: 
Out[34]: 
With this, we’re returning fewer examples within the prompt variable. Allowing us to limit excessive token usage and avoid errors from surpassing the maximum context window of the LLM.
Naturally, prompts are an essential component of the new world of LLMs. It’s worth exploring the tooling made available with Langchain and getting familiar with different prompt engineering techniques.
Here we’ve covered just a few examples of the prompt tooling available in Langchain and a limited exploration of how they can be used. In the next chapter, we’ll explore another essential part of Langchain — called chains — where we’ll see more usage of prompt templates and how they fit into the wider tooling provided by the library.
Resources 
Langchain Handbook Repo 
Next Chapter: 
Chatbot Memory with Langchain 
Comments 
LangChain AI Handbook 
Chapters: 
LangChain: Introduction and Getting Started 
Prompt Engineering and LLMs with Langchain 
Prompt Engineering 
Prompt Templates 
Resources 
Chatbot Memory with Langchain 
Fixing Hallucination with Knowledge Bases 
Superpower LLMs with Conversational Agents in LangChain 
Building Custom Tools for LLM Agents 
Share: 
Twitter 
 
 
Facebook 
 
 
Hacker News 
What will you build?
Upgrade your search or recommendation systems with just a few lines of code, or 
contact us 
 for help.
Create Account 
Pricing 
Docs 
Learn 
Company 
Contact 
Careers 
Support 
© Pinecone Systems, Inc. | San Francisco, CA | 
Terms 
| 
Privacy 
| 
Product Privacy 
| 
Cookies 
| 
Trust & Security 
| 
System Status 
Pinecone is a registered trademark of Pinecone Systems, Inc.
Don’t fill this out if you’re human: 
Get product and article updates 
 
 
 
 
 
 
Get Updates 
Subscribed successfully.
Failed to submit.